\documentclass{ar2rc}

\usepackage{siunitx}
\usepackage{apacite}
\usepackage{physics}

\usepackage[colorinlistoftodos]{todonotes}
\usepackage{color}
\newcommand{\jdg}[1]{\todo[color=red!30]{#1}}
\newcommand{\all}[1]{\todo[color=blue!30]{#1}}

% better lists
\usepackage{enumitem}
\setlist{nosep}

% some commands
\usepackage{xspace}
\makeatletter
\DeclareRobustCommand\onedot{\futurelet\@let@token\@onedot}
\def\@onedot{\ifx\@let@token.\else.\null\fi\xspace}
\def\eg{\emph{e.g}\onedot} \def\Eg{\emph{E.g}\onedot}
\def\ie{\emph{i.e}\onedot} \def\Ie{\emph{I.e}\onedot}
\def\etc{\emph{etc}\onedot} \def\vs{\emph{vs}\onedot}
\newcommand{\usd}[1]{\SI{#1}[\$]{}}

% ACRONYMS
\usepackage[acronym, nopostdot, nonumberlist, shortcuts, numberedsection, nogroupskip,]{glossaries}
\newacronym{bfe}{BFE}{base flood elevation}
\newacronym{cmip}{CMIP}{the Coupled Model Intercomparison Project}
\newacronym{dmdu}{DMDU}{decision making under deep uncertainty}
\newacronym{fema}{FEMA}{the Federal Emergency Management Agency}
\newacronym{gev}{GEV}{generalized extreme value}
\newacronym{hazus}{HAZUS}{Hazard U.S.}
\newacronym{iid}{IID}{independent and identically distributed}
\newacronym{ipcc}{IPCC}{International Panel on Climate Change}
\newacronym{msl}{MSL}{mean relative sea level}
\newacronym{noaa}{NOAA}{the National Oceanic and Atmospheric Administration}
\newacronym{pdf}{PDF}{probability density function}
\newacronym{rcp}{RCP}{representative concentration pathway}
\newacronym{rdm}{RDM}{robust decision making}
\newacronym{slr}{SLR}{sea level rise}
\newacronym{ssp}{SSP}{shared socio-economic pathway}
\newacronym[]{usace}{USACE}{United States Army Corps of Engineers}
\newacronym[]{usgs}{USGS}{United States Geological Survey}
\newacronym[\glslongpluralkey={states of the world}]{sow}{SOW}{state of the world}

% cross-refs
\usepackage{xr-hyper}
\makeatletter
\newcommand*{\addFileDependency}[1]{% argument=file name and extension
  \typeout{(#1)}
  \@addtofilelist{#1}
  \IfFileExists{#1}{}{\typeout{No file #1.}}
}
\makeatother
\newcommand*{\myexternaldocument}[1]{%
    \externaldocument{#1}%
    \addFileDependency{#1.tex}%
    \addFileDependency{#1.aux}%
}
\myexternaldocument{submission_02}
\myexternaldocument{supplemental}

\hypersetup{hidelinks}
\usepackage{cleveref}

\title{A subjective Bayesian framework for synthesizing deep uncertainties in climate risk management}
\author{James Doss-Gollin and Klaus Keller}
\journal{Earth's Future}

\begin{document}

\maketitle

We thank the editors and both referees for their thoughtful, detailed, and extremely constructive comments on our initial submission.

Referee 1 particularly encouraged us to clarify the presentation of our methods and results.
As noted in responses to the specific comments given below, we have attempted to incorporate these suggestions into the revised manuscript.
Referee 2 encouraged us to (1) better contextualize our methodological approach relative to previous works, (2) clarify and improve the mathematical formulation of our approach, and (3) to better describe the usefulness of our method.
In particular, we noted that our manuscript was somewhat unclear about how ``Subjective Bayesian'' tools and methods figure into the actual methods and results presented.

To address these comments and to improve the clarity of the manuscript, we have substantially rewritten the introduction.
We have also pulled the proposed re-weighting method out of section 2.3 and into its own section to highlight that it is a key contribution of this paper.
More generally we have made revisions to the manuscript that (1) reduce redundancies, (2) reduce potentially confusing discussion of methods for Bayesian model selection in the $\mathcal{M}$-open case, and (3) better contextualize our key contributions.
We have also improved grammar and writing style throughout the manuscript.

In the remainder of this document we address the specific comments made by the two referees.
Where appropriate we quote from the revised manuscript using the following convention:
\begin{quote}
    Unchanged text
    \DIFdelbegin \DIFdel{deleted text}\DIFdelend \DIFaddbegin \DIFadd{new text}\DIFaddend.
\end{quote}
We note that the \texttt{trackchanges} \LaTeX package used by the AGU template has some trouble with line breaks and citations and thank the editor and reviewers for their understanding.
\emph{All line numbers referenced in this document refer to the line numbers of the tracked changes document.}

\section{Referee \#1}

\RC{
    This work introduces a Bayesian framework to synthesize and characterize deep uncertainties to merge standard exploratory modeling techniques with more traditional decision support tools that require statistics like the expected value.
    Such statistics, which require weighting sampled states of the world, are problematic in the presence of deep uncertainty.
    The authors argue that many decision making frameworks commonly used for robust decision-making problems actually make such a weighting, but that is not transparent.
    Decisions about the sampling range, joint sampling distribution, and statistics (such as domain criterion) can have consequences for the robustness of the options presented to stakeholders, but this may not be clear.
    The proposed framework allows for a synthesis across deep uncertainties using subjective Bayesian priors.
    The method is demonstrated for a very simple house-raising example including both sea level rise and a stationary storm surge risk.

    Overall, I found the work well written and informative, and I think it is very promising.
    The framework's novelty arises from the way it stitches standard methods from Bayesian statistics and DMDU.
    This is not a negative statement, as I think by employing common-sense methods in a novel way the authors' framework is more likely to gain traction.
    An important contribution is the introduction, which nicely lays out the current state of practice, emerging methods (primarily from the DMDU community), and then research gaps.
    I appreciated the author's care in discussing the difficulty in adopting non-stationary frequency methods for extremes, with key citations to important works by Montanari, Seranaldi, and Bulletin 17C's introduction.
}

\AR{
    Thank you for your comments.
    This is an excellent summary of the aim and scope of this paper.
}

\RC{
    The use of the word model to mean different things. Throughout the manuscript, and particularly in Figure 1, the authors utilize the term `model' to refer to both the combination of RCP-SLR model/assumption and the systems model.
    I found this confusing at multiple places.
    One suggestion is to call the 'models' in box d of Figure 1 'scenarios' or something like that.
    So the scenario is the deep uncertainty (RCP-SLR model) and then the possible futures in box b of Figure 1 are samples drawn from the pdf that's conditioned on the scenario in Box d.
    I think this new terminology would be particularly important if one were to have more than one systems model in box c.
}

\AR{
    Thank you for flagging this as an opportunity to improve clarity.
    After some discussion we have decided to refer to ``scenarios'' (where it adds clarity, ``probabilistic scenarios'') and ``models'' (or ``physical models'' where helpful).
}

\RC{
    I understand the intention of the paper is to showcase the method, not necessarily the results.
    This said, some more discussion about the findings would be helpful.
    For example, in Figure 7A there is a spike after 0 ft of increased height.
    If some detail were given on the construction cost function (taken from another work), and at least a few more sentences on the results, I think it would really improve an already very good manuscript.
}

\AR{
    Thanks for this helpful suggestion.
    We have added some discussion around L599:
}

\begin{quote}
    \DIFdelbegin \DIFdel{This }\DIFdelend \DIFaddbegin \DIFadd{As discussed in \mbox{%DIFAUXCMD
            \cref{sec:analysis-condition}}\hskip0pt%DIFAUXCMD
        , this }\DIFaddend probabilistic interpretation allows us to compute \DIFdelbegin \DIFdel{, for example, expected values }\DIFdelend \DIFaddbegin \DIFadd{expected values of functions}\DIFaddend .
    For example, \cref{fig:tradeoffs-by-rcp}(a) plots the expected total lifetime cost as a function of $\Delta h$ for the sixteen \DIFdelbegin \DIFdel{models }\DIFdelend \DIFaddbegin \DIFadd{probabilistic scenarios }\DIFaddend considered (we highlight three representative models).
    \DIFdelbegin \DIFdel{Similarly, \mbox{%DIFAUXCMD
            \cref{fig:tradeoffs-by-rcp}}\hskip0pt%DIFAUXCMD
        (b) plots the }\DIFdelend \DIFaddbegin \DIFadd{This panel shows }\DIFaddend lifetime expected damages as a function of $\Delta h$\DIFdelbegin \DIFdel{.
    }\DIFdelend \DIFaddbegin \DIFadd{, shown in \mbox{%DIFAUXCMD
            \cref{fig:tradeoffs-by-rcp}}\hskip0pt%DIFAUXCMD
        (b,  plus the up-front cost of construction.
        Because there are high fixed costs associated with building (see cost curve in fig.~S3), it generally does not make sense to raise the house by only a small amount, since this incurs these fixed costs without providing substantial damage reduction.
        \mbox{%DIFAUXCMD
            \Cref{fig:tradeoffs-by-rcp} }\hskip0pt%DIFAUXCMD
        shows that estimates of trade-offs between up-front cost and expected lifetime costs are highly sensitive to the chosen scenario.
    }\DIFaddend For small $\Delta h$, expected costs are low under optimistic \DIFdelbegin \DIFdel{models }\DIFdelend \DIFaddbegin \DIFadd{scenarios }\DIFaddend (\eg, \gls{rcp} 2.6 with slow ice sheet dynamics; red lines) and high under pessimistic \DIFdelbegin \DIFdel{models }\DIFdelend \DIFaddbegin \DIFadd{scenarios }\DIFaddend (\eg, \gls{rcp}8.5 with the DP16 model; blue lines).
    \DIFaddbegin \DIFadd{Estimates of the optimal decision are highly sensitive to the choice of scenario.
    }\DIFaddend For example, under the most pessimistic \DIFdelbegin \DIFdel{model }\DIFdelend \DIFaddbegin \DIFadd{scenario }\DIFaddend (blue line), the cost-minimizing height increase is \SI{6}{ft}, which incurs an up-front cost of 73\% of the house value but reduces lifetime expected damages by over 150\% of house value.
    Under the most optimistic \DIFdelbegin \DIFdel{model }\DIFdelend \DIFaddbegin \DIFadd{scenario }\DIFaddend (gray line), the cost-minimizing decision is to not elevate, as elevating \SI{6}{ft} incurs the same up-front cost yet reduces lifetime expected damages by less than 50\% of house value.
\end{quote}

\RC{
    Line 270: I think more detail should be given, perhaps in the discussion, of the difficulty projecting SOW to some lower dimensional representation may present in more complicated problems.
    Here it is given little attention, which is fine because this is meant to be a simple didactic problem.
    But I could imagine a much more complicated setting, perhaps in a multisector problem, where collapsing the state space of the world presents problems.
    I suggest the authors provide some more discussion of the challenge this may present and how one might overcome it in the discussion.
}

\AR{
    Thank you for this helpful suggestion.
    We agree that this merits further discussion and have briefly added some nuance to the section on limitations and research needs.
    We have also removed extraneous references to Approximate Bayesian Computation.
    See paragraph beginning L678:
}

\begin{quote}
    Several limitations to our study merit further discussion.
    The first category has to do with limitations of the underlying method proposed for re-weighting \glspl{sow}.
    For example, we develop a subjective \DIFdelbegin \DIFdel{prior belief }\DIFdelend \DIFaddbegin \DIFadd{probabilistic model }\DIFaddend $p_\mathrm{belief}(\Psi)$ over \gls{msl} in the year 2100.
    Although this is a low-dimensional representation of the full time series, it is not a sufficient statistic\DIFdelbegin \DIFdel{; prior studies have shown that using Approximate Bayesian Computation to calibrate models on low dimensional statistics using that are not sufficient statistics can lead to biased posterior estimates \mbox{%DIFAUXCMD
            \cite{csillery_abc:2010,marjoram_abc:2006}}\hskip0pt%DIFAUXCMD
        .
        Although we are not performing calibration here,  and this is thus not a direct concern, }\DIFdelend \DIFaddbegin \DIFadd{.
        In other words,  many possible low-dimensional representations are possible and }\DIFaddend time series with the same \gls{msl} in 2100 may differ in other ways\DIFdelbegin \DIFdel{, and experts may have prior information about the likelihood of these differences not represented in our model}\DIFdelend \DIFaddbegin \DIFadd{.
        For problems with more sources of uncertainty, such as multisector problems, choosing an appropriate low-dimensional representation may prove challenging.
        In such settings, diagnostics and sensitivity analyses may shed light on the appropriateness of different modeling choices}\DIFaddend .
\end{quote}

\RC{
    Line 284: One really exciting direction is the opportunity to test the sensitivity of the objective tradeoffs to $p_\textup{belief}$.
    It may be the case that some objectives are not affected by the differences in $p_\textup{belief}$ between stakeholders and so there is no point in getting tied up trying to pin it down.
    I'm not proposing any additional analysis, only that this sort of screening is possible and is consistent with the spirit of exploratory modeling and RDM.
    It would be an interesting exercise, perhaps for follow-on work.
}

\AR{
    Thanks for this helpful suggestion.
    We have added the following text to the paragraph beginning L397.
}

\begin{quote}
    The aim of this re-weighting framework is to integrate an ensemble of \glspl{sow} used for exploratory modeling into formal decision analysis, even when the \glspl{sow} deliberately over- or under-sample some regions of the parameter space.
    As in \cref{sec:analysis-condition}, we must condition on a model: where the analysis of \cref{sec:analysis-condition} conditions upon deep uncertainties, the approach outlined in this subsection synthesizes across them.
    \DIFdelbegin \DIFdel{We reiterate that stakeholders and experts will not, in general, agree on }\DIFdelend \DIFaddbegin \DIFadd{Considering multiple probabilistic models for }\DIFaddend $p_\mathrm{belief}$ \DIFdelbegin \DIFdel{because there is not, even conceptually, an objectively correct choice \mbox{%DIFAUXCMD
            \cite{oreskes_verification:1994,walker_deep:2013}}\hskip0pt%DIFAUXCMD
        .
        However, we posit that since we cannot be ``right, '' it is valuable to maximize the transparency of our implicit probabilistic assumptions, and suggest that writing down an explicit model for }\DIFdelend \DIFaddbegin \DIFadd{can also be useful for understanding the sensitivity of the decision to the choice of $p_\mathrm{belief}$.
        Further, the sensitivity, or lack thereof, of different objectives to the choice of }\DIFaddend $p_\mathrm{belief}$ \DIFdelbegin \DIFdel{supports this aim}\DIFdelend \DIFaddbegin \DIFadd{may be useful for identifying future research needs}\DIFaddend .
\end{quote}

\RC{
    Table 1: I think at least some detail should be given about the elevation cost and depth-damage functions.
    I understand they were taken from another work. This would make interpreting the later results easier.
}

\AR{
    We agree with this suggestion since the shape of these curves matters a lot.
    We have added the following text around L513:
}

\begin{quote}
    Following \citeA{zarekarizi_suboptimal:2020}, we use the \gls{hazus} depth-damage curves provided by \gls{fema}; this depth-damage relationship is shown in \DIFdelbegin \DIFdel{\mbox{%DIFAUXCMD
            \cref{fig:cost-depth-damage}}\hskip0pt%DIFAUXCMD
        .}\DIFdelend \DIFaddbegin \DIFadd{fig.~S1.
    }\DIFaddend For comparison, \DIFdelbegin \DIFdel{\mbox{%DIFAUXCMD
            \cref{fig:cost-depth-damage} }\hskip0pt%DIFAUXCMD
    }\DIFdelend \DIFaddbegin \DIFadd{fig.~S1 }\DIFaddend also shows the ``Europa'' depth-damage relationship developed by the Joint Research Center of the European Commission's science and knowledge service \cite{huizinga_depthdamage:2016}.
    \DIFaddbegin \DIFadd{Both models show damage increasing with flood depth before reaching an upper limit but differ in the value of the upper limit and the rate at which damages approach it.
    }\DIFaddend Although \citeA{zarekarizi_suboptimal:2020} demonstrate that the choice of fragility function is important for informing house elevation, we use only the HAZUS model for simplicity.
\end{quote}

\RC{
    Figure 5b.
    If the intention is to show the agreement of the fitted model with the annual maximum storm surges, a P-P plot might be clearer.
    I leave this up to the authors.
    I have no doubt the GEV is a good fit.
}

\AR{
    Thanks for this suggestion.
    The purpose of this plot is actually not to demonstrate the quality of fit but rather to present the distribution using a ``return period plot'' standard in the flood frequency analysis community.
    As such, we have decided to leave it as is.
    We concur with the reviewer that if the objective were to assess the fit of the model, a P-P plot (along with other model checks) would be more appropriate.
}

\RC{
    Figure 4b.
    There is remarkable disagreement between the models of mean sea level rise.
    It might be worth at least a few sentences commenting on this.
}

\AR{
    Thanks for this suggestion.
    We agree that the differences between models are surprising and relevant.
    We have added the following discussion around L454:
}

\begin{quote}
    \DIFaddbegin \DIFadd{probabilistic scenarios considered.
        The stark differences between different scenarios of \mbox{%DIFAUXCMD
            \gls{slr} }\hskip0pt%DIFAUXCMD
        arise primarily from different representations of Antarctic Ice Sheet contributions to global \mbox{%DIFAUXCMD
            \gls{slr} }\hskip0pt%DIFAUXCMD
        and statistical calibration methodologies.
        For a more detailed discussion we refer the reader to \mbox{%DIFAUXCMD
            \citeA{ruckert_coastal:2019}}\hskip0pt%DIFAUXCMD
        .
    }\DIFaddend
\end{quote}

\RC{
    Equation 4: it might be helpful to define $p$ here.
}

\AR{
    Thanks for this suggestion to clarify our notation.
    This text around L511 now reads:
}

\begin{quote}
    The expected annual damage is thus
    \begin{equation*}\label{eq:ead}
        \textrm{EAD}(t) = \mathbb{E}[D \qty(h-\overline{y}(t))] = \int_{y'} p(y') D \qty(h - \qty(\overline{y}(t) + y')) \dd{y'},
    \end{equation*}
    where $D(h-y)$ is a deterministic function specifying damage as a function of flood depth (relative to the house) \DIFaddbegin \DIFadd{and $p(y')$ is the probability density of storm surge}\DIFaddend .
\end{quote}

\RC{
    Line 416: The use of the gamma distribution is quite sensible but is presented without justification.
    This might be worth just a short sentence on why it was chosen.
}

\AR{
    Thanks for this suggestion.
    We have explained our choice and have also taken the opportunity to clarify that these distributions are illustrative choices.
    See around L550:
}

\begin{quote}
    We use a Gamma distribution for all three priors, parameterized following \DIFdelbegin \DIFdel{\mbox{%DIFAUXCMD
            \cref{eq:gamma-dist}}\hskip0pt%DIFAUXCMD
        .}\DIFdelend \DIFaddbegin \DIFadd{eq.~(S4).
        The distributions were chosen to be illustrative, rather than to reflect any particular scientific consensus.
        The Gamma distribution is a flexible distribution that can be used to model skewed, lower-bounded distributions, making it an appropriate choice for modeling subjective uncertainty about \mbox{%DIFAUXCMD
            \gls{slr}}\hskip0pt%DIFAUXCMD
        .
    }\DIFaddend \Cref{tab:slr-priors} specifies the parameters of these distributions, as well as some quantiles of the distributions.
    Their \glspl{pdf} are also plotted in \cref{fig:lsl-priors-weights}(A).
\end{quote}

\RC{
    Figure 8: The y-axis labels on B-D should be more descriptive.
}

\AR{
    Thanks for this suggestion.
    We have moved the previous labels to the title and added ``implicit weight assigned'' to the $y$ axis labels.
}

\section{Referee \#2}

\RC{
    This manuscript addresses an important topic: the role of probabilistic methods in decision-making under deep uncertainty.
    The authors point out that scenario-based DMDU methods implicitly put probabilities on scenarios but do not make these assumptions transparent.
    They address this by developing a method to calculate the weights implicitly applied to each deeply uncertain scenario.
    I applaud this effort -- the tension between scenario-based methods that use optimization and probabilistic methods is an important and understudied one.
    I also see a lot of value in how the authors have framed the problem and described the pros and cons of scenario-based DMDU methods and probabilistic methods for CBA in the context of infrastructure design.
    The simple case study of raising the elevation of a house under flood risk affected by deeply uncertain sea level rise is appropriate for demonstrating the method and is technically sound.
}

\AR{
    Thank you for these comments.
    This is an excellent summary of the goals and broader context of this work.
}

\RC{
    However, I have three major concerns that prevent me from recommending the manuscript for publication in its current form.
    I defer to the editor on whether, assuming all these concerns are addressed in revision, the contribution warrants publication in Earth's Future.
}

\AR{
    Thanks for the detailed and thoughtful comments.
    We address them below in greater detail
}

\RC{
    First, the paper is not well grounded in previous literature at the intersection of Bayesian /probabilistic methods and DMDU.
    This has led the authors to make overly broad claims about their contribution that make it difficult to discern what they are adding beyond existing methods.
    It is certainly not true that ``In this paper we offer a first conceptual step towards bridging the fields of DMDU and Bayesian model building'' as claimed in line 183.
    Here are some papers that integrate Bayesian/probabilistic methods into DMDU contexts:
    \citeA{reis_distribution:2020},
    \citeA{taner_probabilistic:2019},
    \citeA{hui_adaptive:2018},
    \citeA{fletcher_learning:2019}, and
    \citeA{fletcher_groundwater:2019}.
    The first three are especially similar to the authors' contributions; the authors need to make a compelling argument for what their approach adds beyond this existing literature.
}

\AR{
    Thanks very much for this helpful comment.
    This comment underscores a need for improved clarity in the introduction to the manuscript; as noted, there are numerous papers that use probabilistic tools, including Bayesian methods, in DMDU contexts.
    In our revised introduction we have clarified that there is a long literature on the relative merits of probabilistic vs non-probabilistic information in DMDU contexts, as noted in \citeA{taner_probabilistic:2019}, but that this debate has often centered on a top-down, technocratic, objectivist philosophy of probability in which there is explicitly or implicitly assumed to be a true probability distribution.
    Our contribution is to outline how a subjective Bayesian philosophical approach can address many of the concerns raised by critics of probabilistic approaches while providing a principled and transparent method for reasoning about uncertainty.
}

\begin{quote}
    %DIFDELCMD < %%%
    \DIFdel{We are motivated by parallels between decision making under deep uncertainty and the statistical problem of model selection.
        \mbox{%DIFAUXCMD
            \citeA{oreskes_verification:1994} }\hskip0pt%DIFAUXCMD
        argues that because natural }\DIFdelend \DIFaddbegin \DIFadd{The limitations of objectivist approaches to projecting risk extend beyond estimating nonstationary climate hazards.
        Human-natural }\DIFaddend systems are never closed and model results are never unique, \DIFaddbegin \DIFadd{and thus }\DIFaddend validation and verification of models representing these systems is necessarily qualitative and subjective \DIFdelbegin \DIFdel{.
        In the literature on decision making under deep uncertainty, this has led to recognition of the need to develop strategies }\DIFdelend \DIFaddbegin \DIFadd{\mbox{%DIFAUXCMD
            \cite{oreskes_verification:1994}}\hskip0pt%DIFAUXCMD
        .
        In other words, no model exists that could represent the full truth, and the future is thus deeply uncertain \mbox{%DIFAUXCMD
            \cite{keller_management:2021,walker_deep:2013,lempert_complex:2002,haasnoot_sealevelrise:2021}}\hskip0pt%DIFAUXCMD
        .
        Consequently, a growing literature on \mbox{%DIFAUXCMD
            \gls{dmdu} }\hskip0pt%DIFAUXCMD
        emphasizes the value of identifying decisions }\DIFaddend that are robust\DIFaddbegin \DIFadd{, in some sense, to deep uncertainties \mbox{%DIFAUXCMD
            \cite{moody_robustness:2013,herman:2015,mcphail_robustness:2019,borgomeo_robustness:2018}}\hskip0pt%DIFAUXCMD
        .
        Within this literature has emerged a debate regarding the value and use of probabilistic information  \mbox{%DIFAUXCMD
            \cite<see>[and references therein]{taner_probabilistic:2019}}\hskip0pt%DIFAUXCMD
        .
        On the one hand, scholars have pointed out that predictions are inherently unreliable, and representing deep uncertainties through probability distributions frequently over-estimates predictive skill \mbox{%DIFAUXCMD
            \cite{groves_scenarios:2007,lempert_robust:2000}}\hskip0pt%DIFAUXCMD
        .
        On the other, assessments of which decisions are robust depend on subjective choices about how to define robustness and how to sample uncertainties \mbox{%DIFAUXCMD
            \cite{mcphail_robustness:2019,quinn_exploratory:2020,schneider_scenarios:2002,schneider_dangerous:2001,reis_distribution:2020}}\hskip0pt%DIFAUXCMD
        .
    }
\end{quote}

\AR{

    We specifically clarify this is not a first conceptual step towards using probabilistic/Bayesian methods in DMDU contexts.
}

\begin{quote}
    \DIFadd{In this paper we offer a conceptual step towards bridging this divide by presenting a framework that is designed to combine the strengths of both approaches.
        In the first step, exploratory or bottom-up modeling is used }\DIFaddend
    \ldots
\end{quote}

\AR{
    Several of the references provided use stochastic dynamic programming (SDP) to in DMDU contexts.
    This work is necessarily probabilistic and involves an updating step with parallels to Bayesian updating.
    We have referenced this literature in the discussion in two places.
    As discussed in the second point, however, these methods still make explicit or implicit assumptions about the likelihood of different futures, and so our approach is complementary.
}

\begin{quote}
    \DIFaddbegin \DIFadd{Based on this analysis, we would recommend that the owner if this hypothetical home elevate by approximately 4-6}\si{ft}\DIFadd{.
        Alternatively, the homeowner could choose to defer the deicision of whether, and how high, to elevate; our analysis did not consider this possibility but there is a rich literature on flexible design and engineering options analysis in climate risk analysis \mbox{%DIFAUXCMD
            \cite<\eg,>{fletcher_learning:2019,fletcher_groundwater:2019,hui_adaptive:2018,garner_slrise:2018,herman_control:2020,deneufville_eoa_theory:2019}}\hskip0pt%DIFAUXCMD
        .
    }\DIFaddend
\end{quote}

\begin{quote}
    Yet although framing the decision through a sequential lens can increase adaptability and improve outcomes \cite{fletcher:2017,garner_slrise:2018}, \DIFdelbegin \DIFdel{the optimized policy rules are necessarily }\DIFdelend \DIFaddbegin \DIFadd{decisions and outcomes remain highly }\DIFaddend sensitive to the characterization of uncertainty \DIFaddbegin \DIFadd{\mbox{%DIFAUXCMD
            \cite{herman_control:2020}}\hskip0pt%DIFAUXCMD
    }\DIFaddend , and thus the problem of synthesizing across deep uncertainties remains \DIFdelbegin \DIFdel{\mbox{%DIFAUXCMD
            \cite{herman_control:2020}}\hskip0pt%DIFAUXCMD
    }\DIFdelend \DIFaddbegin \DIFadd{relevant}\DIFaddend .
\end{quote}


\RC{
    My second key concern is that the mathematical formulation is not clear and complete, and it is not always clear how the sample application aligns with the general framework.
    Given that the authors suggest the mathematical formulation is a key part of their contribution, this is important.
    Specifically:
    The method is framed both in the introduction (lines 157-182) and methods section (lines 240-250) around Bayesian model selection.
    However, it is not clear if or how the authors are performing Bayesian model selection.
}

\AR{
    This is an important insight and a helpful comment.
    Although our approach is motivated by methods for Bayesian model selection, we are not actually implementing these methods directly.
    Moreover, we are not performing Bayesian inference at all.
    We have increased clarity by significantly condensing the references to Bayesian model selection in the Introduction, and by clarifications of language made in response to other comments (\eg, removing references to $p_\mathrm{belief}$ as priors; see below).
}

\RC{
    In figure 1e and line 247, the authors provide a conditional probability of $u$ given $x_i$ and $M_k$, and state this is the result of IID draws from $M_k$.
    This is similar to the $p(y|M_k)$ term in the classical BMA framework from \citeA{raftery_bma:2005} equation 1.
    Does this imply that there is a Bayesian posterior for model weights developed?
    If so, what is it?
    What data is used for the updating and what is the likelihood function? It is unclear if or how Bayes' is used here.
}

\AR{
    Thanks very much for this detailed and insightful comment.
    For reference, equation 1 of \citeA{raftery_bma:2005} is
    $$p(y) = \frac{1}{K} \sum_{k=1}^K p(y|M_k) p(M_k | y^T),$$
    ``where $p( y | M_k)$ is the forecast PDF based on model $M_k$ alone, and $p(M_k | y^T)$ is the posterior probability of model $M_k$ being correct given the training data, and reflects how well model $M_k$ fits the training data.''

    This comment is closely related to the previous comment in that we draw inspiration from the literature on Bayesian model selection but do not explicitly perform it.
    Our approach is conceptually similar to BMA as noted (and even closer to stacking; see \cite{Yao:2018bu}).
    There are two key differences.
    First, these methods focus on estimating the weights assigned to each model from data; in our context we have no data.
    As discussed in response to a previous comment, future work could consider adaptive decision making (by revisiting the decision at multiple time steps, \ie stochastic control) in which case there would be data available in the future that could be used to estimate these weights as in the SDP papers referenced.
    Second, these methods assign weights to each model, whereas we assign weights to each SOW.
    This is motivated by the fact that the SOWs in our applications, and in many climate adaptation applications, are computationally expensive to generate, and we want to use every one for both exploratory modeling and decision making.
}

\RC{
    Shortly later in the paragraph under section 2.3, the authors take an expected value of $f(s)$ and state that it ``can be readily estimated as $\frac{1}{N} \sum_{j=1}^N f(\bf{s}_j)$.''
    I believe this is inconsistent with the interpretation of the SOW being samples from an underlying distribution.
    We know that:
    $$\mathbb{E}\qty[f(s)]=\sum_{s \in \Omega}f(s)P_s(s)$$
    where $P_s$ is the probability mass function of $s$.
    This is equivalent to the authors' equation above only when assuming that $P_s(s)$ is a discrete uniform RV where each SOW gets equal probability.
    However, this seems to be at odds with the authors interpretation that the SOW are IID draws from some underlying distribution of models.
    If that is the case, the probability mass or density function shouldn't simply put probability on the available SOW, as these are merely samples from an underlying distribution.
    It conflates the sample with the population.
    If, for example, the SOW were believed to be IID samples from a lognormal distribution, the we would expect an estimate for $\mathbb{E}\qty[f(s)]$ that is asymmetric across the $f(s)$ in different SOW, not an unweighted average.
}

\AR{
    Thanks for this very usfeul comment.
    As we note in the text, the Naive Monte Carlo estimate $\frac{1}{N} \sum_{j=1}^N f(\bf{s}_j)$ is appropriate when the SOWs are IID draws from the ``target'' or ``population'' distribution.
    This is valid even if the underlying distribution is not Uniform; for example, the mean of draws from a lognormal distribution will approach the true mean of the distribution as $n \rightarrow \infty$ following the Central Limit Theorem.
    However, we are motivated by problems where generating samples is computationally expensive, and thus rather than draw new samples from a target distribution we propose to re-weight existing samples.
    Our approach is agnostic to the specific form of the sampling distribution.
    We have clarified the relevant paragraph as follows.
    We also correct a mistake in the original text; if $\sum_{i=1}^J w_j =1$ then the $\frac{1}{N}$ should not be included.
    See the paragraph around L370:
}

\begin{quote}
    \DIFadd{A particular need is to estimate the expectation of functions over \mbox{%DIFAUXCMD
            \glspl{sow} }\hskip0pt%DIFAUXCMD
        (}\ie\DIFadd{, box e in \mbox{%DIFAUXCMD
            \cref{fig:flowchart}}\hskip0pt%DIFAUXCMD
        ).
        If the $J$ }\DIFaddend \glspl{sow} are drawn \gls{iid} from \DIFdelbegin \DIFdel{the true distribution, }\DIFdelend \DIFaddbegin \DIFadd{some distribution that credibly represents the true likelihood of different futures }\DIFaddend then the expected value of \DIFdelbegin \DIFdel{some function$f$, $\mathbb{E}\qty[f(\vb{s})]$}\DIFdelend \DIFaddbegin \DIFadd{such a function}\DIFaddend , \DIFaddbegin \DIFadd{$f(\mathbf{s})$, }\DIFaddend can be readily \DIFdelbegin \DIFdel{estimated as $\frac{1}{N} \sum_{j=1}^N f(\vb{s}_j)$}\DIFdelend \DIFaddbegin \DIFadd{approximated using the Monte Carlo estimate $\mathbb{E}\qty[f(\vb{s})] \approx \frac{1}{N} \sum_{j=1}^N f(\vb{s}_j)$}\DIFaddend .
    However, this is often not the case\DIFdelbegin \DIFdel{; for example, a fixed set of simulations may be available for analysis or low-probability but high-impact regions of the parameter space may have been sampled }\DIFdelend \DIFaddbegin \DIFadd{.
        For example, in \mbox{%DIFAUXCMD
            \cref{sec:case-study} }\hskip0pt%DIFAUXCMD
        we will consider decision analysis where the \mbox{%DIFAUXCMD
            \glspl{sow} }\hskip0pt%DIFAUXCMD
        are sampled from multiple physical models and \mbox{%DIFAUXCMD
            \gls{rcp} }\hskip0pt%DIFAUXCMD
        scenarios, considering that not all \mbox{%DIFAUXCMD
            \gls{rcp} }\hskip0pt%DIFAUXCMD
        scenarios are equally likely and that not all physical models are equally skillful}\DIFaddend .
    In this case, the formula \DIFdelbegin \DIFdel{must }\DIFdelend \DIFaddbegin \DIFadd{may }\DIFaddend be adjusted to \DIFaddbegin \DIFadd{a weighted Monte Carlo estimate:
    }\DIFaddend \begin{equation*}
        \mathbb{E}\qty[f(\vb{s})] \approx \DIFdelbegin \DIFdel{\frac{1}{N} }\DIFdelend \sum_{i=j}^N w_j f(\vb{s}_j),
    \end{equation*}
    where \DIFdelbegin \DIFdel{the $w_j$ are suitably chosen weights such that their sum is equal to 1.
    }\DIFdelend \DIFaddbegin \DIFadd{$\sum_{j=1}^J w_j = 1$.
    }\DIFaddend
\end{quote}

\RC{
    I am further confused by equation 1 and the following paragraph on choosing the weights.
    First, are the weights “chosen” by the analyst, as stated in line 266, or are they estimated as a way of making clear what weights are implied by a certain selection of SOW?
}

\AR{
    Thanks for this comment.
    We hope that the revised text shown above (paragraph around L370) clarifies this point by removing reference to ``suitably chosen''.
    The next paragraph of the text discusses how to estimate the weights; we emphasize that the weights (applied to \glspl{sow}) are implied by a particular choice for $p(\psi)$.
    See L373:
}

\begin{quote}
    The challenge then becomes to suitably estimate the $w_j$.
    \DIFdelbegin \DIFdel{Paralleling }\DIFdelend \DIFaddbegin \DIFadd{Many such methods exist; drawing from }\DIFaddend joint probability methods for statistical analysis of tropical cyclones, we \DIFdelbegin \DIFdel{use }\DIFdelend \DIFaddbegin \DIFadd{employ }\DIFaddend a grid-based approach \cite{johnson_clara:2013,resio_probabilities:2007,toro_jpm-os:2010}.
    First, we project the \glspl{sow} $\vb{s} \in \Omega$ onto a low-dimensional representation, which we denote $\qty{\psi_1, \psi_2, \ldots, \psi_J} \in \Psi$.
    Then, we partition the parameter space into a region corresponding to each \gls{sow} and integrating the \DIFdelbegin \DIFdel{\mbox{%DIFAUXCMD
            \gls{pdf} }\hskip0pt%DIFAUXCMD
        $p_\mathrm{belief}$ }\DIFdelend \DIFaddbegin \DIFadd{probability $p(\psi)$ }\DIFaddend over each region.

    \DIFaddbegin \DIFadd{Doing so requires a probabilistic model for this low-dimensional representation of the \mbox{%DIFAUXCMD
            \glspl{sow}}\hskip0pt%DIFAUXCMD
        ,  $p(\psi)$.
        We denote this model $p_\mathrm{belief}$ to emphasize that it represents a subjective belief about the \mbox{%DIFAUXCMD
            \glspl{sow}}\hskip0pt%DIFAUXCMD
        , rather than an objectively verifiable choice.
        In general we do not expect that stakeholders and experts will agree on $p_\mathrm{belief}$ because there is not, even conceptually, an objectively correct choice \mbox{%DIFAUXCMD
            \cite{oreskes_verification:1994,walker_deep:2013}}\hskip0pt%DIFAUXCMD
        .
        However, we posit that since we cannot be ``right,'' it is valuable to maximize the transparency of our implicit probabilistic assumptions, and suggest that writing down an explicit model for $p_\mathrm{belief}$ supports this aim.
        Choices for $p_\mathrm{belief}$ can be drawn from many sources, including expert elicitation or  results of previous analyses.
        These models can be interpreted as prior beliefs about \mbox{%DIFAUXCMD
            \gls{slr} }\hskip0pt%DIFAUXCMD
        that could be incorporated into a Bayesian analysis as additional data is collected in the future, and thus can draw from literature on Bayesian prior selection and prior predictive checks \mbox{%DIFAUXCMD
            \cite{gelman_workflow:2020}}\hskip0pt%DIFAUXCMD
        .
    }
\end{quote}

\RC{
    Second, what is the mathematical basis for equation 2?
    The description in 267- 272 describes the method illustrated in figure 2 but doesn't justify it, and I could not find the method in the references provided.
    It seems like the approach is a way of approximating some unknown continuous distribution of $M_k$ using the discrete sampled SOW, but the authors do not state this.
    If this is true, it could potentially be used to address my comment above about conflating sample and population.
}

\AR{
    Thanks for this comment.
    We hope that the revised text shown in response to the previous comment (around L370) clarifies the mathematical basis for equation 2 as a weighted Monte Carlo estimate.
    This is a separate problem from the method disciussed in the next paragraph for estimating the weights using grid-based approaches.
    To add a small amount of clarity to the description of the approach provided, the proposed approach is a way for approximating some target continuous distribution over \glspl{sow} using the discrete sampled SOW.
    As discussed above, we model the probability distribution over \glspl{sow} rather than over models, which distinguishes our approach from methods such as BMA.
}

\RC{
    Finally, I am confused how the application in section 4.3 is equivalent to this.
    Line 413 states ``we construct three probabilistic models for $p_\textup{belief}$'' and then refers to these models in line 418 as ``priors''.
    The use of the word “prior” implies a Bayesian model.
    Does this suggest that equation (2) is meant to be a prior distribution? It is not described that way in section 2.3. If so, what is the posterior? What is the likelihood? My interpretation is that the “target distribution” in figure 2 is F belief, but that the weights over SOW are just an approximation of that, not a posterior.
}

\AR{
    Thanks for this very helpful comment.
    We agree that this language was confusing.
    Although we can interpret these distributions as prior beliefes about the future that could be updated should we recieve information in the future, we now refer to ``subjective probability distributions'' rather than ``subjective priors'' to reduce confusion.
}

\RC{
    It is clear the storm surge model in 3.2 uses a Bayesian model to fit a GEV using historical storm surge data.
    But this is presented as a probabilistic uncertainty, not a deep uncertainty, so it remains unclear how Bayesian methods are used to synthesize deep uncertainties.
}

\AR{
    Thanks for this comment.
    We have clarified the text to emphasize that storm surge is treated probabilistically.
    The only source of uncertainty that we treat as deeply uncertain is sea level rise.
    See Table 1 and also L412:
}

\begin{quote}
    To illustrate the proposed decision analytic framework, we model a one-time decision of whether to elevate a house, and if so by how much (\cref{fig:xlrm}).
    Following the approach outlined in \citeA{zarekarizi_suboptimal:2020}, we focus on a case study of a \emph{hypothetical} house in Norfolk, VA.
    For interpretability, we focus on deep uncertainty in \gls{msl} and \DIFdelbegin \DIFdel{approximate }\DIFdelend \DIFaddbegin \DIFadd{treat storm surge and }\DIFaddend other model parameters as shallow uncertainties as shown in \cref{tab:uncertainties}.
\end{quote}

\RC{
    It is not clear to me if there is an error in the mathematical presentation or if it simply needs to be clarified. It is possible also that this is a valid probabilistic framework, but not a Bayesian one, in which case the approach would need to be substantially reframed. If I have misunderstood due to lack of clarity in the presentation, I welcome a clarification from the authors.
}

\AR{
    We hope that the comments and clarifications have shed light on this concern.
}

\RC{
    My final key critique is that I think the authors need to make a more compelling case for the usefulness of their approach relative to existing DMDU methods to warrant
    publication. If I am interpreting correctly, the two new aspects of the method are 1) the conditioning step (section 2.2 which I believe though am not sure is the same as what is applied in section 4.2) and 2) the deep uncertainty synthesis. The key result from the conditioning step is show in Figures 6 and 7. It seems to me that Figure 6 is quite similar to visuals commonly used in exploratory analysis like parallel axis plots or scatter plots showing the results against different objectives across SOWs. Take as an example Figure 6 from Quinn et al. 2020. This plot shows frequency and severity of water shortage as measured by cumulative frequency across SOWs in the experiment, visualized with darker colors for more SOWs. This is a common type of figure in exploratory analysis used to transparently visualize the results across SOW. The authors figure 6 seems quite similar to this. What is more useful or transparent about your conditioning approach? I mean that as a genuine question – I have found the methods difficult to follow and would appreciate clarification from the authors.
}

\AR{
    Thanks for this comment.
    Figure 6 is presented as an exploratory analysis.
    That is, we use it to identify potential system vulnerabilities without consideration of how likely different \glspl{sow} are.
    It is similar to the figure referenced or to parallel axis plots, but presents the information in a different way.
    Figure 6 of \citeA{quinn_exploratory:2020} shows the cumulative distribution function (CDF) of water shortage across \glspl{sow}.
    Estimating the CDF which an implicit or explicit model for different SOWs.
    In that paper the \glspl{sow} are sampled Uniformly within a neighborhood around point estimates (specifically, the maximum likelihood estimates of the parameters of a Hidden Markov Model).

    As the key contribution of this paper is the synthesis approach, the results that illustrate this approach (figures 8 and 9) are probably the most relevant.
    We hope that the revised introduction and abstract more clearly convey the utility of the proposed synthesis approach.
    We also hope that pulling the re-weighting method into a separate section highlights that it is a key component of this paper.
}

\RC{
    Similarly, Figure 8 shows the key results from the weighting step.
    As I understand it, panel a shows the authors illustrative assumptions for sea level rise distributions, and then panels b-d show what weights across SOWs are consistent with those assumptions. What should a decision maker takeaway from this? How might they use it in their decision process? It would be helpful to see this articulated in the example and expanded on in the discussion or conclusions.
}

\AR{
    Thanks for this suggestion.
    We have added some discussion to the text of how decision analysts can use this approach.
    We have also clarified that the weights are computed as the sum of weights assigned to each \gls{sow} drawn from a particular model.
    We hope this will make clear that we are modeling the probability of \glspl{sow} rather than of different scenarios.
}

\begin{quote}
    One application of this method is to diagnose \DIFdelbegin \DIFdel{which assumptions }\DIFdelend \DIFaddbegin \DIFadd{the assumptions which which }\DIFaddend different $p_\mathrm{belief}$ are consistent\DIFdelbegin \DIFdel{with}\DIFdelend .
    \Cref{fig:lsl-priors-weights}(B-D) shows the total weight that each \DIFdelbegin \DIFdel{prior }\DIFdelend \DIFaddbegin \DIFadd{choice of $p_\mathrm{belief}$ }\DIFaddend assigns to \glspl{sow} generated by each \gls{rcp} scenario and physical model.
    \DIFaddbegin \DIFadd{Specifically, weights are computed as the sum of weights assigned to each \mbox{%DIFAUXCMD
            \gls{sow} }\hskip0pt%DIFAUXCMD
        sampled from that model.
    }\DIFaddend For example, the rapid \gls{slr} scenario (green line in \cref{fig:lsl-priors-weights}) places most weight on \DIFaddbegin \DIFadd{\mbox{%DIFAUXCMD
            \glspl{sow} }\hskip0pt%DIFAUXCMD
        produced by }\DIFaddend the DP16 model, and particularly on \gls{rcp} 8.5 which by some accounts is unlikely given current policy \cite{hausfather_scenarios:2020,srikrishnan_probabilistic:2022}.
    Conversely, the slow \gls{slr} scenario (red line) places most weight on the BRICK models, particularly \gls{rcp} 2.6 \cite<also unlikely given current policy;>{hausfather_scenarios:2020,srikrishnan_probabilistic:2022} \DIFdelbegin \DIFdel{) }\DIFdelend and \gls{rcp} 4.5.
    The uncertain \gls{slr} scenario (blue line) allocates approximately equal weight across models.
    \DIFaddbegin \DIFadd{Decision analysts can use this approach as a diagnostic to understand the assumptions implicit to their choice of $p_\mathrm{belief}$.
    }\DIFaddend
\end{quote}

% ugly hack to hide month in APACite
\renewcommand{\APACrefYearMonthDay}[3]{\APACrefYear{#1}}
\bibliographystyle{apacite}
\bibliography{library-bibtex}

\end{document}
